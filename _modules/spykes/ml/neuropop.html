

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>spykes.ml.neuropop &mdash; spykes  documentation</title>
  

  
  
  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  

  
    <link rel="stylesheet" href="../../../_static/gallery.css" type="text/css" />
  

  
        <link rel="index" title="Index"
              href="../../../genindex.html"/>
        <link rel="search" title="Search" href="../../../search.html"/>
    <link rel="top" title="spykes  documentation" href="../../../index.html"/>
        <link rel="up" title="Module code" href="../../index.html"/> 

  
  <script src="../../../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../../index.html" class="icon icon-home"> spykes
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../getting-started.html">Getting Started</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../getting-started.html#what-is-spykes">What is Spykes?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../getting-started.html#installing">Installing</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../getting-started.html#vanilla">Vanilla</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../getting-started.html#bleeding-edge">Bleeding-Edge</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../getting-started.html#local-version">Local Version</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../getting-started.html#datasets">Datasets</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorial.html">Tutorials</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorial.html#fitting-tuning-curves-with-gradient-descent">Fitting Tuning Curves with Gradient Descent</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorial.html#special-case-1-poisson-generalized-linear-model-glm">Special Case 1: Poisson Generalized Linear Model (GLM)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorial.html#special-case-2-generalized-von-mises-model-gvm">Special Case 2: Generalized von Mises Model (GVM)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorial.html#minimizing-negative-log-likelihood-with-gradient-descent">Minimizing Negative Log Likelihood with Gradient Descent</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorial.html#decoding-feature-from-population-activity">Decoding Feature from Population Activity</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../auto_examples/index.html">Examples Gallery</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../auto_examples/plot_neuropop_simul_example.html">Neuropop Example</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/plot_neuropop_simul_example.html#create-a-neuropop-object">Create a NeuroPop object</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/plot_neuropop_simul_example.html#simulate-a-population-of-neurons">Simulate a population of neurons</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/plot_neuropop_simul_example.html#split-into-training-and-testing-sets">Split into training and testing sets</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/plot_neuropop_simul_example.html#fit-the-tuning-curves-with-gradient-descent">Fit the tuning curves with gradient descent</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/plot_neuropop_simul_example.html#predict-the-population-activity-with-the-fit-tuning-curves">Predict the population activity with the fit tuning curves</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/plot_neuropop_simul_example.html#score-the-prediction">Score the prediction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/plot_neuropop_simul_example.html#plot-the-simulated-and-fit-tuning-curves">Plot the simulated and fit tuning curves</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/plot_neuropop_simul_example.html#decode-feature-from-the-population-activity">Decode feature from the population activity</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/plot_neuropop_simul_example.html#visualize-ground-truth-vs-decoded-estimates">Visualize ground truth vs. decoded estimates</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/plot_neuropop_simul_example.html#score-decoding-performance">Score decoding performance</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../auto_examples/plot_popvis_example.html">PopVis Example</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/plot_popvis_example.html#initialization">0 Initialization</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../auto_examples/plot_popvis_example.html#download-data">0.1 Download Data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../auto_examples/plot_popvis_example.html#read-in-data">0.2 Read In Data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../auto_examples/plot_popvis_example.html#initialize-variables">0.3 Initialize Variables</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/plot_popvis_example.html#popvis">1 PopVis</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../auto_examples/plot_popvis_example.html#initiate-all-neurons">1.1 Initiate all Neurons</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../auto_examples/plot_popvis_example.html#get-event-times">1.2 Get Event Times</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../auto_examples/plot_popvis_example.html#create-popvis-object">1.3 Create PopVis Object</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../auto_examples/plot_crcns_dataset_example.html">CRCNS DataSet Example</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/plot_crcns_dataset_example.html#overview-reproduce-figure">0 Overview: Reproduce Figure</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../auto_examples/plot_crcns_dataset_example.html#article">0.1 Article</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../auto_examples/plot_crcns_dataset_example.html#dataset">0.2 Dataset</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/plot_crcns_dataset_example.html#data">1 Data</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../auto_examples/plot_crcns_dataset_example.html#download-data">1.1 Download Data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../auto_examples/plot_crcns_dataset_example.html#load-data">1.2 Load Data</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/plot_crcns_dataset_example.html#get-spike-times">2 Get Spike Times</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/plot_crcns_dataset_example.html#get-event-times">3 Get Event Times</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/plot_crcns_dataset_example.html#get-features">4 Get Features</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/plot_crcns_dataset_example.html#define-features">5 Define Features</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/plot_crcns_dataset_example.html#plots">6 Plots</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../auto_examples/plot_crcns_dataset_example.html#rasters">6.1 Rasters</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../auto_examples/plot_crcns_dataset_example.html#psth">6.2 PSTH</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../auto_examples/plot_crcns_dataset_example.html#reproduce-figure">6.3 Reproduce Figure</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../auto_examples/plot_crcns_dataset_example.html#ggplot">6.4 ggplot</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../auto_examples/plot_neuropixels_example.html">Neuropixels Example</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/plot_neuropixels_example.html#neuropixels">Neuropixels</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/plot_neuropixels_example.html#download-data">0 Download Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/plot_neuropixels_example.html#read-in-data">1 Read In Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/plot_neuropixels_example.html#create-data-frame">2 Create Data Frame</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/plot_neuropixels_example.html#start-plotting">3 Start Plotting</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../auto_examples/plot_neuropixels_example.html#striatum">3.1 Striatum</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../auto_examples/plot_neuropixels_example.html#frontal">3.2 Frontal</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../auto_examples/plot_neuropixels_example.html#all-neurons">3.3 All Neurons</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../auto_examples/plot_neuropixels_example.html#striatum-vs-motor-cortex">3.4 Striatum vs. Motor Cortex</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../auto_examples/plot_neural_coding_reward_example.html">Neural Coding Reward Example</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/plot_neural_coding_reward_example.html#overview-reproduce-figure">0 Overview: Reproduce Figure</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../auto_examples/plot_neural_coding_reward_example.html#article">0.1 Article</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../auto_examples/plot_neural_coding_reward_example.html#dataset">0.2 Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../auto_examples/plot_neural_coding_reward_example.html#initialization">0.3 Initialization</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/plot_neural_coding_reward_example.html#first-graph-of-panel-a">1 First Graph of Panel A</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../auto_examples/plot_neural_coding_reward_example.html#initiate-all-neurons">1.1 Initiate all Neurons</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../auto_examples/plot_neural_coding_reward_example.html#get-event-times">1.2 Get Event Times</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../auto_examples/plot_neural_coding_reward_example.html#match-peak-velocities">1.3 Match Peak Velocities</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../auto_examples/plot_neural_coding_reward_example.html#plot-psths">1.4 Plot PSTHs</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/plot_neural_coding_reward_example.html#first-graph-of-panel-c">2 First Graph of Panel C</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../auto_examples/plot_neural_coding_reward_example.html#normalize-psths">2.1 Normalize PSTHs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../auto_examples/plot_neural_coding_reward_example.html#find-population-average">2.2 Find Population Average</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../auto_examples/plot_neural_coding_reward_example.html#plot-psth">2.3 Plot PSTH</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../auto_examples/plot_reaching_dataset_example.html">Reaching Dataset Example</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/plot_reaching_dataset_example.html#initialization">Initialization</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../auto_examples/plot_reaching_dataset_example.html#download-reaching-dataset">Download Reaching Dataset</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/plot_reaching_dataset_example.html#part-i-neurovis">Part I: NeuroVis</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../auto_examples/plot_reaching_dataset_example.html#instantiate-example-pmd-neuron">Instantiate Example PMd Neuron</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../auto_examples/plot_reaching_dataset_example.html#raster-plot-and-psth-aligned-to-target-onset">Raster plot and PSTH aligned to target onset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../auto_examples/plot_reaching_dataset_example.html#events">Events</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../auto_examples/plot_reaching_dataset_example.html#features">Features</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../auto_examples/plot_reaching_dataset_example.html#example-1-reward-vs-no-reward">Example 1: Reward vs No Reward</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../auto_examples/plot_reaching_dataset_example.html#example-2-according-to-quadrant-of-reaching-direction">Example 2: according to quadrant of reaching direction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../auto_examples/plot_reaching_dataset_example.html#example-3-same-as-example-2-but-for-an-m1-neuron-and-aligned-at-gocuetime">Example 3: Same as Example 2 but for an M1 neuron and aligned at goCueTime</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../auto_examples/plot_reaching_dataset_example.html#example-4-sorted-by-direction-only-for-the-trials-with-reward">Example 4: sorted by direction only for the trials with reward</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/plot_reaching_dataset_example.html#part-ii-neuropop">Part II: NeuroPop</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../auto_examples/plot_reaching_dataset_example.html#extract-reach-direction-x">Extract reach direction x</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../auto_examples/plot_reaching_dataset_example.html#extract-m1-spike-counts-y">Extract M1 spike counts Y</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../auto_examples/plot_reaching_dataset_example.html#split-into-train-and-test-sets">Split into train and test sets</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../auto_examples/plot_reaching_dataset_example.html#create-an-instance-of-neuropop">Create an instance of NeuroPop</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../auto_examples/plot_reaching_dataset_example.html#predict-firing-rates">Predict firing rates</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../auto_examples/plot_reaching_dataset_example.html#score-the-prediction">Score the prediction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../auto_examples/plot_reaching_dataset_example.html#visualize-tuning-curves">Visualize tuning curves</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../auto_examples/plot_reaching_dataset_example.html#decode-reach-direction-from-population-vector">Decode reach direction from population vector</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../auto_examples/plot_reaching_dataset_example.html#visualize-decoded-reach-direction">Visualize decoded reach direction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../auto_examples/plot_reaching_dataset_example.html#score-decoding-performance">Score decoding performance</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../contributing.html">Contributing</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../contributing.html#guidelines">Guidelines</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../contributing.html#testing">Testing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../contributing.html#building-documentation">Building Documentation</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../api/plot.html">Plotting</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../api/plot.html#module-spykes.plot.neurovis">NeuroVis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/plot.html#module-spykes.plot.popvis">PopVis</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/ml.html">Machine Learning</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../api/ml.html#module-spykes.ml.neuropop">NeuroPop</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/ml.html#module-spykes.ml.strf">STRF</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/io.html">Input / Output</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../api/io.html#datasets">Datasets</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/config.html">Config</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/utils.html">Utils</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">spykes</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../../index.html">Module code</a> &raquo;</li>
        
      <li>spykes.ml.neuropop</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for spykes.ml.neuropop</h1><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">absolute_import</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">copy</span> <span class="k">import</span> <span class="n">deepcopy</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">from</span> <span class="nn">..</span> <span class="k">import</span> <span class="n">utils</span>


<div class="viewcode-block" id="NeuroPop"><a class="viewcode-back" href="../../../api/ml.html#spykes.ml.neuropop.NeuroPop">[docs]</a><span class="k">class</span> <span class="nc">NeuroPop</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;Implements conveniences for plotting, fitting and decoding.</span>

<span class="sd">    Implements convenience methods for plotting, fitting and decoding</span>
<span class="sd">    population tuning curves. We allow the fitting of two classes of parametric</span>
<span class="sd">    tuning curves.</span>

<span class="sd">    Two types of models are available. `The Generalized von Mises model by</span>
<span class="sd">    Amirikan &amp; Georgopulos (2000) &lt;http://brain.umn.edu/pdfs/BA118.pdf&gt;`_ is</span>
<span class="sd">    defined by</span>

<span class="sd">    .. math::</span>

<span class="sd">        f(x) = b_ + g_ * exp(k_ * cos(x - mu_))</span>
<span class="sd">        f(x) = b_ + g_ * exp(k1_ * cos(x) + k2_ * sin(x))</span>

<span class="sd">    The Poisson generalized linear model is defined by</span>

<span class="sd">    .. math::</span>

<span class="sd">        f(x) = exp(k0_ + k_ * cos(x - mu_))</span>
<span class="sd">        f(x) = exp(k0_ + k1_ * cos(x) + k2_ * sin(x))</span>

<span class="sd">    Args:</span>
<span class="sd">        tunemodel (str): Can be either :data:`gvm`, the Generalized von Mises</span>
<span class="sd">            model, or :data:`glm`, the Poisson generalized linear model.</span>
<span class="sd">        n_neurons (float): Number of neurons in the population.</span>
<span class="sd">        random_state (int): Seed for :data:`numpy.random`.</span>
<span class="sd">        eta (float): Linearizes the exponent above :data:`eta`.</span>
<span class="sd">        learning_rate (float): The learning rate for fitting.</span>
<span class="sd">        convergence_threshold (float): The convergence threshold.</span>
<span class="sd">        maxiter (float): Max number of iterations.</span>
<span class="sd">        n_repeats (float): Number of repetitions.</span>
<span class="sd">        verbose (bool): Whether to print convergence and loss at each</span>
<span class="sd">            iteration.</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">tunemodel</span><span class="o">=</span><span class="s1">&#39;glm&#39;</span><span class="p">,</span>
                 <span class="n">n_neurons</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                 <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                 <span class="n">eta</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span>
                 <span class="n">learning_rate</span><span class="o">=</span><span class="mf">2e-1</span><span class="p">,</span>
                 <span class="n">convergence_threshold</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span>
                 <span class="n">maxiter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
                 <span class="n">n_repeats</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                 <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tunemodel</span> <span class="o">=</span> <span class="n">tunemodel</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_neurons</span> <span class="o">=</span> <span class="n">n_neurons</span>

        <span class="c1"># Assign random tuning parameters</span>
        <span class="c1"># --------------------------------</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mu_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_neurons</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k0_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_neurons</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_neurons</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k1_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_neurons</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k2_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_neurons</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">g_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_neurons</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_neurons</span><span class="p">)</span>
        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">random_state</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="n">tunemodel</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_neurons</span><span class="p">)))</span>

        <span class="c1"># Assign optimization parameters</span>
        <span class="c1"># -------------------------------</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eta</span> <span class="o">=</span> <span class="n">eta</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">convergence_threshold</span> <span class="o">=</span> <span class="n">convergence_threshold</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">maxiter</span> <span class="o">=</span> <span class="n">maxiter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_repeats</span> <span class="o">=</span> <span class="n">n_repeats</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>

    <span class="k">def</span> <span class="nf">default_mu</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="p">(</span><span class="mf">2.0</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="o">-</span> <span class="mf">1.0</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">default_k0</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">tunemodel</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="k">if</span> <span class="n">tunemodel</span> <span class="o">==</span> <span class="s1">&#39;glm&#39;</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">default_k</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
        <span class="k">return</span> <span class="mf">20.0</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">default_g</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">tunemodel</span><span class="p">):</span>
        <span class="k">return</span> <span class="mf">5.0</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="k">if</span> <span class="n">tunemodel</span> <span class="o">==</span> <span class="s1">&#39;gvm&#39;</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">default_b</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">tunemodel</span><span class="p">):</span>
        <span class="k">return</span> <span class="mf">10.0</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="k">if</span> <span class="n">tunemodel</span> <span class="o">==</span> <span class="s1">&#39;gvm&#39;</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>

<div class="viewcode-block" id="NeuroPop.set_params"><a class="viewcode-back" href="../../../api/ml.html#spykes.ml.neuropop.NeuroPop.set_params">[docs]</a>    <span class="k">def</span> <span class="nf">set_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tunemodel</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">neurons</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">k0</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                   <span class="n">k</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">g</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;A function that sets tuning curve parameters as specified.</span>

<span class="sd">        If any of the parameters is None, it is randomly initialized for all</span>
<span class="sd">        neurons.</span>

<span class="sd">        Args:</span>
<span class="sd">            tunemodel (str): Either &#39;gvm&#39; or &#39;glm&#39;.</span>
<span class="sd">            neurons (list): A list of integers which specifies the subset of</span>
<span class="sd">                neurons to set.</span>
<span class="sd">            mu (float): :data:`len(neurons) x 1`, feature of interest.</span>
<span class="sd">            k0 (float): :data:`len(neurons) x 1`, baseline.</span>
<span class="sd">            k (float): :data:`len(neurons) x 1`, gain.</span>
<span class="sd">            g (float): :data:`len(neurons) x 1`, gain.</span>
<span class="sd">            b (float): :data:`len(neurons) x 1`, baseline.</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="c1"># Does an argument check on &quot;tunemodel&quot;.</span>
        <span class="k">if</span> <span class="n">tunemodel</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">tunemodel</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="s1">&#39;gvm&#39;</span><span class="p">,</span> <span class="s1">&#39;glm&#39;</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Invalid value for `tunemodel`: Expected either &#39;</span>
                             <span class="s1">&#39;&quot;gvm&quot; or &quot;glm&quot;, but got &quot;</span><span class="si">{}</span><span class="s1">&quot;.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tunemodel</span><span class="p">))</span>

        <span class="c1"># Disambiguates some paremeters to use.</span>
        <span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tunemodel</span> <span class="k">if</span> <span class="n">tunemodel</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">tunemodel</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_neurons</span><span class="p">))</span> <span class="k">if</span> <span class="n">neurons</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">neurons</span>
        <span class="n">n_neurons</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="s1">&#39;__len__&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="mi">1</span>

        <span class="c1"># Updates the model&#39;s parameters to be the specified values.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mu_</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">default_mu</span><span class="p">(</span><span class="n">n_neurons</span><span class="p">)</span> <span class="k">if</span> <span class="n">mu</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">mu</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k0_</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">default_k0</span><span class="p">(</span><span class="n">n_neurons</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span> <span class="k">if</span> <span class="n">k0</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">k0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">g_</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">default_g</span><span class="p">(</span><span class="n">n_neurons</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span> <span class="k">if</span> <span class="n">g</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">g</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b_</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">default_b</span><span class="p">(</span><span class="n">n_neurons</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span> <span class="k">if</span> <span class="n">b</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">b</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k_</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">default_k</span><span class="p">(</span><span class="n">n_neurons</span><span class="p">)</span> <span class="k">if</span> <span class="n">k</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">k</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k1_</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">k_</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mu_</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k2_</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">k_</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mu_</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span></div>

    <span class="k">def</span> <span class="nf">_tunefun</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">k0</span><span class="p">,</span> <span class="n">k1</span><span class="p">,</span> <span class="n">k2</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;Defines the tuning function as specified in self.tunemodel.</span>

<span class="sd">        Args:</span>
<span class="sd">            x (float): :data:`n_samples x 1`, feature of interest.</span>
<span class="sd">            k0 (float): :data:`n_neurons x 1`, baseline.</span>
<span class="sd">            k1 (float): :data:`n_neurons x 1`, convenience parameter.</span>
<span class="sd">            k2 (float): :data:`n_neurons x 1`, convenience parameter.</span>
<span class="sd">            g (float): :data:`n_neurons x 1`, gain.</span>
<span class="sd">            b (float): :data:`n_neurons x 1`, baseline.</span>

<span class="sd">        Returns</span>
<span class="sd">            array: :data:`n_samples x 1` array, the firing rates.</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">b</span> <span class="o">+</span> <span class="n">g</span> <span class="o">*</span> <span class="n">utils</span><span class="o">.</span><span class="n">slow_exp</span><span class="p">(</span><span class="n">k0</span> <span class="o">+</span> <span class="n">k1</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">k2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">),</span>
                                   <span class="bp">self</span><span class="o">.</span><span class="n">eta</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">y</span>

    <span class="k">def</span> <span class="nf">_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">k0</span><span class="p">,</span> <span class="n">k1</span><span class="p">,</span> <span class="n">k2</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;The loss function, negative Poisson log likelihood.</span>

<span class="sd">        This is the negative Poisson log likelihood under the von Mises tuning</span>
<span class="sd">        model.</span>

<span class="sd">        Args:</span>
<span class="sd">            x (float): :data:`n_samples x 1` (encoding) or</span>
<span class="sd">                a scalar (decoding), feature of interest.</span>
<span class="sd">            y (float): :data:`n_samples x 1` (encoding) or</span>
<span class="sd">                :data:`n_neurons x 1` (decoding), firing rates.</span>
<span class="sd">            mu (float): :data:`n_neurons x 1`, preferred feature</span>
<span class="sd">                :data:`[-pi, pi]`.</span>
<span class="sd">            k0 (float): :data:`n_neurons x 1`, baseline.</span>
<span class="sd">            k1 (float): :data:`n_neurons x 1`, convenience parameter.</span>
<span class="sd">            k2 (float): :data:`n_neurons x 1`, convenience parameter.</span>
<span class="sd">            g (float): :data:`n_neurons x 1`, gain.</span>
<span class="sd">            b (float): :data:`n_neurons x 1`, baseline.</span>

<span class="sd">        Returns:</span>
<span class="sd">            scalar float: The loss, a scalar float.</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="n">lmb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tunefun</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">k0</span><span class="p">,</span> <span class="n">k1</span><span class="p">,</span> <span class="n">k2</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
        <span class="n">J</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">lmb</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y</span> <span class="o">*</span> <span class="n">lmb</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">J</span>

    <span class="k">def</span> <span class="nf">_grad_theta_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tunemodel</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">k0</span><span class="p">,</span> <span class="n">k1</span><span class="p">,</span> <span class="n">k2</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;The gradient of the loss function for the parameters of the model.</span>

<span class="sd">        Args:</span>
<span class="sd">            x (float array): :data:`n_samples x 1`, feature of interest.</span>
<span class="sd">            y (float array): :data:`n_samples x 1`, firing rates.</span>
<span class="sd">            k0 (float array): :data:`n_neurons x 1`, baseline.</span>
<span class="sd">            k1 (float array): :data:`n_neurons x 1`, convenience parameter.</span>
<span class="sd">            k2 (float array): :data:`n_neurons x 1`, convenience parameter.</span>
<span class="sd">            g (float): Scalar, gain.</span>
<span class="sd">            b (float): Scalar, baseline.</span>

<span class="sd">        Returns:</span>
<span class="sd">            tuple: The gradients of the loss with respect to each parameter.</span>

<span class="sd">            * :data:`grad_k0`: scalar</span>
<span class="sd">            * :data:`grad_k1`: scalar</span>
<span class="sd">            * :data:`grad_k2`: scalar</span>
<span class="sd">            * :data:`grad_g`: scalar</span>
<span class="sd">            * :data:`grad_b`: scalar</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="n">lmb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tunefun</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">k0</span><span class="p">,</span> <span class="n">k1</span><span class="p">,</span> <span class="n">k2</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>

        <span class="n">n_samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">float</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">grad_k1</span> <span class="o">=</span> <span class="mf">1.</span> <span class="o">/</span> <span class="n">n_samples</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">g</span> <span class="o">*</span> <span class="n">utils</span><span class="o">.</span><span class="n">grad_slow_exp</span><span class="p">(</span><span class="n">k0</span> <span class="o">+</span> <span class="n">k1</span> <span class="o">*</span>
                                          <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">k2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">),</span>
                                          <span class="bp">self</span><span class="o">.</span><span class="n">eta</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span>
                                          <span class="mi">1</span> <span class="o">-</span> <span class="n">y</span> <span class="o">/</span> <span class="n">lmb</span><span class="p">))</span>
        <span class="n">grad_k2</span> <span class="o">=</span> <span class="mf">1.</span> <span class="o">/</span> <span class="n">n_samples</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">g</span> <span class="o">*</span> <span class="n">utils</span><span class="o">.</span><span class="n">grad_slow_exp</span><span class="p">(</span><span class="n">k0</span> <span class="o">+</span> <span class="n">k1</span> <span class="o">*</span>
                                          <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">k2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">),</span>
                                          <span class="bp">self</span><span class="o">.</span><span class="n">eta</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">*</span>
                                          <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">y</span> <span class="o">/</span> <span class="n">lmb</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">tunemodel</span> <span class="o">==</span> <span class="s1">&#39;glm&#39;</span><span class="p">:</span>
            <span class="n">grad_k0</span> <span class="o">=</span> <span class="mf">1.</span> <span class="o">/</span> <span class="n">n_samples</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">utils</span><span class="o">.</span><span class="n">grad_slow_exp</span><span class="p">(</span><span class="n">k0</span> <span class="o">+</span> <span class="n">k1</span> <span class="o">*</span>
                                              <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">k2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">),</span>
                                              <span class="bp">self</span><span class="o">.</span><span class="n">eta</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">y</span> <span class="o">/</span> <span class="n">lmb</span><span class="p">))</span>
            <span class="n">grad_g</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="n">grad_b</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">elif</span> <span class="n">tunemodel</span> <span class="o">==</span> <span class="s1">&#39;gvm&#39;</span><span class="p">:</span>
            <span class="n">grad_k0</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="n">grad_g</span> <span class="o">=</span> <span class="mf">1.</span> <span class="o">/</span> <span class="n">n_samples</span> <span class="o">*</span>\
                <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">utils</span><span class="o">.</span><span class="n">slow_exp</span><span class="p">(</span><span class="n">k0</span> <span class="o">+</span> <span class="n">k1</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">k2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">),</span>
                                      <span class="bp">self</span><span class="o">.</span><span class="n">eta</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">y</span> <span class="o">/</span> <span class="n">lmb</span><span class="p">))</span>
            <span class="n">grad_b</span> <span class="o">=</span> <span class="mf">1.</span> <span class="o">/</span> <span class="n">n_samples</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">y</span> <span class="o">/</span> <span class="n">lmb</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">grad_k0</span><span class="p">,</span> <span class="n">grad_k1</span><span class="p">,</span> <span class="n">grad_k2</span><span class="p">,</span> <span class="n">grad_g</span><span class="p">,</span> <span class="n">grad_b</span>

    <span class="k">def</span> <span class="nf">_grad_x_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">k0</span><span class="p">,</span> <span class="n">k1</span><span class="p">,</span> <span class="n">k2</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;The gradient of the loss function with respect to X.</span>

<span class="sd">        Args:</span>
<span class="sd">            x (float): Scalar, feature of interest.</span>
<span class="sd">            y (float array): :data:`n_neurons x 1`, firing rates.</span>
<span class="sd">            k0 (float array): :data:`n_neurons x 1`, baseline.</span>
<span class="sd">            k1 (float array): :data:`n_neurons x 1`, convenience parameter.</span>
<span class="sd">            k2 (float array): :data:`n_neurons x 1`, convenience parameter.</span>
<span class="sd">            g (float array): :data:`n_neurons x 1`, gain.</span>
<span class="sd">            b (float array): :data:`n_neurons x 1`, baseline.</span>

<span class="sd">        Returns:</span>
<span class="sd">            array: :data:`grad_x`, the gradient with respect to :data:`x`.</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="n">n_neurons</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_neurons</span><span class="p">)</span>

        <span class="n">lmb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tunefun</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">k0</span><span class="p">,</span> <span class="n">k1</span><span class="p">,</span> <span class="n">k2</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
        <span class="n">grad_x</span> <span class="o">=</span> <span class="mf">1.</span> <span class="o">/</span> <span class="n">n_neurons</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">g</span> <span class="o">*</span> <span class="n">utils</span><span class="o">.</span><span class="n">grad_slow_exp</span><span class="p">(</span><span class="n">k0</span> <span class="o">+</span> <span class="n">k1</span> <span class="o">*</span>
                                                                 <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span>
                                                                 <span class="n">k2</span> <span class="o">*</span>
                                                                 <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">),</span>
                                                                 <span class="bp">self</span><span class="o">.</span><span class="n">eta</span><span class="p">)</span> <span class="o">*</span>
                                         <span class="p">(</span><span class="n">k2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">-</span> <span class="n">k1</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="o">*</span>
                                         <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">y</span> <span class="o">/</span> <span class="n">lmb</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">grad_x</span>

<div class="viewcode-block" id="NeuroPop.simulate"><a class="viewcode-back" href="../../../api/ml.html#spykes.ml.neuropop.NeuroPop.simulate">[docs]</a>    <span class="k">def</span> <span class="nf">simulate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tunemodel</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">winsize</span><span class="o">=</span><span class="mi">200</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;Simulates firing rates from a neural population.</span>

<span class="sd">        Simulates firing rates from a neural population by randomly sampling</span>
<span class="sd">        circular variables (feature of interest), as well as parameters</span>
<span class="sd">        (:data:`mu`, :data:`k0`, :data:`k`, :data:`g`, :data:`b`).</span>

<span class="sd">        Args:</span>
<span class="sd">            tunemodel (str): Can be either :data:`gvm`, the Generalized von</span>
<span class="sd">                Mises model, or :data:`glm`, the Poisson generalized linear</span>
<span class="sd">                model.</span>
<span class="sd">            n_samples (int): Number of samples required.</span>
<span class="sd">            winsize (float): Time interval in which to simulate spike counts,</span>
<span class="sd">                milliseconds.</span>

<span class="sd">        Returns:</span>
<span class="sd">            tuple: The simulation parameters.</span>

<span class="sd">            * `x`, :data:`n_samples x 1` array, features of interest</span>
<span class="sd">            * `Y`, :data:`n_samples x n_neurons` array, population activity</span>
<span class="sd">            * `mu`, :data:`n_neurons x 1` array, preferred feature,</span>
<span class="sd">              :data:`[-pi, pi]`; `k0`, :data:`n_neurons x 1`, baseline</span>
<span class="sd">            * `k`, :data:`n_neurons x 1` array, shape (width)</span>
<span class="sd">            * `g`, :data:`n_neurons x 1` array, gain</span>
<span class="sd">            * `b`, :data:`n_neurons x 1`, baseline</span>
<span class="sd">        &#39;&#39;&#39;</span>

        <span class="c1"># Sample parameters randomly</span>
        <span class="n">mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="p">(</span><span class="mf">2.0</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_neurons</span><span class="p">)</span> <span class="o">-</span> <span class="mf">1.0</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">tunemodel</span> <span class="o">==</span> <span class="s1">&#39;glm&#39;</span><span class="p">:</span>
            <span class="n">k0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_neurons</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">k0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_neurons</span><span class="p">)</span>

        <span class="n">k</span> <span class="o">=</span> <span class="mf">20.0</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_neurons</span><span class="p">)</span>

        <span class="n">k1</span> <span class="o">=</span> <span class="n">k</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">mu</span><span class="p">)</span>
        <span class="n">k2</span> <span class="o">=</span> <span class="n">k</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">mu</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">tunemodel</span> <span class="o">==</span> <span class="s1">&#39;gvm&#39;</span><span class="p">:</span>
            <span class="n">g</span> <span class="o">=</span> <span class="mf">5.0</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_neurons</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">g</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_neurons</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">tunemodel</span> <span class="o">==</span> <span class="s1">&#39;gvm&#39;</span><span class="p">:</span>
            <span class="n">b</span> <span class="o">=</span> <span class="mf">10.0</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_neurons</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_neurons</span><span class="p">)</span>

        <span class="c1"># Sample features of interest randomly [-pi, pi]</span>
        <span class="n">x</span> <span class="o">=</span> <span class="mf">2.0</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span>

        <span class="c1"># Calculate firing rates under the desired model</span>
        <span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">n_samples</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_neurons</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_neurons</span><span class="p">):</span>
            <span class="c1"># Compute the spike count under the tuning model for given window</span>
            <span class="c1"># size</span>
            <span class="n">lam</span> <span class="o">=</span> <span class="mf">1e-3</span> <span class="o">*</span> <span class="n">winsize</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tunefun</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">k0</span><span class="p">[</span><span class="n">n</span><span class="p">],</span> <span class="n">k1</span><span class="p">[</span><span class="n">n</span><span class="p">],</span> <span class="n">k2</span><span class="p">[</span><span class="n">n</span><span class="p">],</span> <span class="n">g</span><span class="p">[</span><span class="n">n</span><span class="p">],</span>
                                                 <span class="n">b</span><span class="p">[</span><span class="n">n</span><span class="p">])</span>

            <span class="c1"># Sample Poisson distributed spike counts and convert back to</span>
            <span class="c1"># firing rate</span>
            <span class="n">Y</span><span class="p">[:,</span> <span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1e3</span> <span class="o">/</span> <span class="n">winsize</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">poisson</span><span class="p">(</span><span class="n">lam</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">k0</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">b</span></div>

<div class="viewcode-block" id="NeuroPop.predict"><a class="viewcode-back" href="../../../api/ml.html#spykes.ml.neuropop.NeuroPop.predict">[docs]</a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;Predicts the firing rates for the population.</span>

<span class="sd">        Computes the firing rates for the population based on the fit or</span>
<span class="sd">        specified tuning models.</span>

<span class="sd">        Args:</span>
<span class="sd">            x (float): :data:`n_samples x 1`, feature of interest.</span>

<span class="sd">        Returns:</span>
<span class="sd">            float array: :data:`n_samples x n_neurons`, population activity.</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="n">n_samples</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">n_samples</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_neurons</span><span class="p">])</span>
        <span class="c1"># For each neuron</span>
        <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_neurons</span><span class="p">):</span>
            <span class="c1"># Compute the firing rate under the von Mises model</span>
            <span class="n">Y</span><span class="p">[:,</span> <span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tunefun</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">k0_</span><span class="p">[</span><span class="n">n</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">k1_</span><span class="p">[</span><span class="n">n</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">k2_</span><span class="p">[</span><span class="n">n</span><span class="p">],</span>
                                    <span class="bp">self</span><span class="o">.</span><span class="n">g_</span><span class="p">[</span><span class="n">n</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_</span><span class="p">[</span><span class="n">n</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">Y</span></div>

<div class="viewcode-block" id="NeuroPop.fit"><a class="viewcode-back" href="../../../api/ml.html#spykes.ml.neuropop.NeuroPop.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">Y</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;Fits the parameters of the model.</span>

<span class="sd">        Estimate the parameters of the tuning curve under the model specified</span>
<span class="sd">        by :meth:`tunemodel`, given features and population activity.</span>

<span class="sd">        Args:</span>
<span class="sd">            x (float): :data:`n_samples x 1`, feature of interest.</span>
<span class="sd">            Y (float): :data:`n_samples x n_neurons`, population activity.</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">if</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">Y</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>

        <span class="n">learning_rate</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span>
        <span class="n">convergence_threshold</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">convergence_threshold</span>
        <span class="n">n_repeats</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_repeats</span>
        <span class="n">maxiter</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">maxiter</span>

        <span class="c1"># Fit model for each neuron</span>
        <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_neurons</span><span class="p">):</span>

            <span class="c1"># Collect parameters for each repeat</span>
            <span class="n">fit_params</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>

            <span class="c1"># Repeat several times over random initializations</span>
            <span class="c1"># (global optimization)</span>
            <span class="k">for</span> <span class="n">repeat</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_repeats</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tunemodel</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
                <span class="n">fit_params</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s1">&#39;k0&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">k0_</span><span class="p">[</span><span class="n">n</span><span class="p">],</span> <span class="s1">&#39;k1&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">k1_</span><span class="p">[</span><span class="n">n</span><span class="p">],</span>
                                   <span class="s1">&#39;k2&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">k2_</span><span class="p">[</span><span class="n">n</span><span class="p">],</span> <span class="s1">&#39;g&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">g_</span><span class="p">[</span><span class="n">n</span><span class="p">],</span>
                                   <span class="s1">&#39;b&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_</span><span class="p">[</span><span class="n">n</span><span class="p">],</span> <span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">})</span>

                <span class="c1"># Collect loss and delta loss for each iteration</span>
                <span class="n">L</span><span class="p">,</span> <span class="n">DL</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(),</span> <span class="nb">list</span><span class="p">()</span>

                <span class="c1"># Gradient descent iterations (local optimization)</span>
                <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">maxiter</span><span class="p">):</span>

                    <span class="n">converged</span> <span class="o">=</span> <span class="kc">False</span>

                    <span class="c1"># Compute gradients</span>
                    <span class="n">grad_k0_</span><span class="p">,</span> <span class="n">grad_k1_</span><span class="p">,</span> <span class="n">grad_k2_</span><span class="p">,</span> <span class="n">grad_g_</span><span class="p">,</span> <span class="n">grad_b_</span> <span class="o">=</span> \
                        <span class="bp">self</span><span class="o">.</span><span class="n">_grad_theta_loss</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tunemodel</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">Y</span><span class="p">[:,</span> <span class="n">n</span><span class="p">],</span>
                                              <span class="n">fit_params</span><span class="p">[</span><span class="n">repeat</span><span class="p">][</span><span class="s1">&#39;k0&#39;</span><span class="p">],</span>
                                              <span class="n">fit_params</span><span class="p">[</span><span class="n">repeat</span><span class="p">][</span><span class="s1">&#39;k1&#39;</span><span class="p">],</span>
                                              <span class="n">fit_params</span><span class="p">[</span><span class="n">repeat</span><span class="p">][</span><span class="s1">&#39;k2&#39;</span><span class="p">],</span>
                                              <span class="n">fit_params</span><span class="p">[</span><span class="n">repeat</span><span class="p">][</span><span class="s1">&#39;g&#39;</span><span class="p">],</span>
                                              <span class="n">fit_params</span><span class="p">[</span><span class="n">repeat</span><span class="p">][</span><span class="s1">&#39;b&#39;</span><span class="p">])</span>

                    <span class="c1"># Update parameters</span>
                    <span class="n">fit_params</span><span class="p">[</span><span class="n">repeat</span><span class="p">][</span><span class="s1">&#39;k1&#39;</span><span class="p">]</span> <span class="o">=</span>\
                        <span class="n">fit_params</span><span class="p">[</span><span class="n">repeat</span><span class="p">][</span><span class="s1">&#39;k1&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">grad_k1_</span>
                    <span class="n">fit_params</span><span class="p">[</span><span class="n">repeat</span><span class="p">][</span><span class="s1">&#39;k2&#39;</span><span class="p">]</span> <span class="o">=</span>\
                        <span class="n">fit_params</span><span class="p">[</span><span class="n">repeat</span><span class="p">][</span><span class="s1">&#39;k2&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">grad_k2_</span>

                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tunemodel</span> <span class="o">==</span> <span class="s1">&#39;glm&#39;</span><span class="p">:</span>
                        <span class="n">fit_params</span><span class="p">[</span><span class="n">repeat</span><span class="p">][</span><span class="s1">&#39;k0&#39;</span><span class="p">]</span> <span class="o">=</span>\
                            <span class="n">fit_params</span><span class="p">[</span><span class="n">repeat</span><span class="p">][</span><span class="s1">&#39;k0&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">grad_k0_</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tunemodel</span> <span class="o">==</span> <span class="s1">&#39;gvm&#39;</span><span class="p">:</span>
                        <span class="n">fit_params</span><span class="p">[</span><span class="n">repeat</span><span class="p">][</span><span class="s1">&#39;g&#39;</span><span class="p">]</span> <span class="o">=</span>\
                            <span class="n">fit_params</span><span class="p">[</span><span class="n">repeat</span><span class="p">][</span><span class="s1">&#39;g&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">grad_g_</span>
                        <span class="n">fit_params</span><span class="p">[</span><span class="n">repeat</span><span class="p">][</span><span class="s1">&#39;b&#39;</span><span class="p">]</span> <span class="o">=</span>\
                            <span class="n">fit_params</span><span class="p">[</span><span class="n">repeat</span><span class="p">][</span><span class="s1">&#39;b&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">grad_b_</span>

                    <span class="c1"># Update loss</span>
                    <span class="n">L</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">Y</span><span class="p">[:,</span> <span class="n">n</span><span class="p">],</span>
                                        <span class="n">fit_params</span><span class="p">[</span><span class="n">repeat</span><span class="p">][</span><span class="s1">&#39;k0&#39;</span><span class="p">],</span>
                                        <span class="n">fit_params</span><span class="p">[</span><span class="n">repeat</span><span class="p">][</span><span class="s1">&#39;k1&#39;</span><span class="p">],</span>
                                        <span class="n">fit_params</span><span class="p">[</span><span class="n">repeat</span><span class="p">][</span><span class="s1">&#39;k2&#39;</span><span class="p">],</span>
                                        <span class="n">fit_params</span><span class="p">[</span><span class="n">repeat</span><span class="p">][</span><span class="s1">&#39;g&#39;</span><span class="p">],</span>
                                        <span class="n">fit_params</span><span class="p">[</span><span class="n">repeat</span><span class="p">][</span><span class="s1">&#39;b&#39;</span><span class="p">]))</span>

                    <span class="c1"># Update delta loss and check for convergence</span>
                    <span class="k">if</span> <span class="n">t</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                        <span class="n">DL</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">L</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">L</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">])</span>
                        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">DL</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">L</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="o">&lt;</span> <span class="n">convergence_threshold</span><span class="p">:</span>
                            <span class="n">converged</span> <span class="o">=</span> <span class="kc">True</span>

                    <span class="c1"># Back out gain from k1 and k2</span>
                    <span class="n">fit_params</span><span class="p">[</span><span class="n">repeat</span><span class="p">][</span><span class="s1">&#39;k&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span>
                        <span class="n">fit_params</span><span class="p">[</span><span class="n">repeat</span><span class="p">][</span><span class="s1">&#39;k1&#39;</span><span class="p">]</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">+</span>
                        <span class="n">fit_params</span><span class="p">[</span><span class="n">repeat</span><span class="p">][</span><span class="s1">&#39;k2&#39;</span><span class="p">]</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>

                    <span class="c1"># Back out preferred feature (mu) from k1 and k2</span>
                    <span class="n">fit_params</span><span class="p">[</span><span class="n">repeat</span><span class="p">][</span><span class="s1">&#39;mu&#39;</span><span class="p">]</span> <span class="o">=</span> \
                        <span class="n">np</span><span class="o">.</span><span class="n">arctan2</span><span class="p">(</span><span class="n">fit_params</span><span class="p">[</span><span class="n">repeat</span><span class="p">][</span><span class="s1">&#39;k2&#39;</span><span class="p">],</span>
                                   <span class="n">fit_params</span><span class="p">[</span><span class="n">repeat</span><span class="p">][</span><span class="s1">&#39;k1&#39;</span><span class="p">])</span>

                    <span class="c1"># Check for convergence</span>
                    <span class="k">if</span> <span class="n">converged</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                        <span class="k">break</span>

                <span class="c1"># Store the converged loss function</span>
                <span class="n">msg</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="se">\t</span><span class="s1">Converged. Loss function: </span><span class="si">{0:.2f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">L</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
                <span class="c1"># logger.info(msg)</span>
                <span class="c1"># logger.info(&#39;\tdL/L: {0:.6f}\n&#39;.format(DL[-1] / L[-1]))</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
                <span class="n">fit_params</span><span class="p">[</span><span class="n">repeat</span><span class="p">][</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">L</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

            <span class="c1"># Assign the global optimum</span>
            <span class="n">amin</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">d</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">fit_params</span><span class="p">])</span><span class="o">.</span><span class="n">argmin</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mu_</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="n">fit_params</span><span class="p">[</span><span class="n">amin</span><span class="p">][</span><span class="s1">&#39;mu&#39;</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">k0_</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="n">fit_params</span><span class="p">[</span><span class="n">amin</span><span class="p">][</span><span class="s1">&#39;k0&#39;</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">k1_</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="n">fit_params</span><span class="p">[</span><span class="n">amin</span><span class="p">][</span><span class="s1">&#39;k1&#39;</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">k2_</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="n">fit_params</span><span class="p">[</span><span class="n">amin</span><span class="p">][</span><span class="s1">&#39;k2&#39;</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">k_</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="n">fit_params</span><span class="p">[</span><span class="n">amin</span><span class="p">][</span><span class="s1">&#39;k&#39;</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">g_</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="n">fit_params</span><span class="p">[</span><span class="n">amin</span><span class="p">][</span><span class="s1">&#39;g&#39;</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">b_</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="n">fit_params</span><span class="p">[</span><span class="n">amin</span><span class="p">][</span><span class="s1">&#39;b&#39;</span><span class="p">]</span></div>

<div class="viewcode-block" id="NeuroPop.decode"><a class="viewcode-back" href="../../../api/ml.html#spykes.ml.neuropop.NeuroPop.decode">[docs]</a>    <span class="k">def</span> <span class="nf">decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Y</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;Estimates the features that generated a given population activity.</span>

<span class="sd">        Args:</span>
<span class="sd">            Y (float): :data:`n_samples x n_neurons`, population activity.</span>

<span class="sd">        Returns:</span>
<span class="sd">            float array: :data:`n_samples x 1`, feature of interest.</span>
<span class="sd">        &#39;&#39;&#39;</span>

        <span class="n">n_samples</span> <span class="o">=</span> <span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="n">maxiter</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">maxiter</span>
        <span class="n">learning_rate</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span>
        <span class="n">convergence_threshold</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">convergence_threshold</span>

        <span class="c1"># Initialize feature</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="p">(</span><span class="mf">2.0</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span> <span class="o">-</span> <span class="mf">1.0</span><span class="p">)</span>

        <span class="c1"># For each sample</span>
        <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">):</span>

            <span class="c1"># Collect loss and delta loss for each iteration</span>
            <span class="n">L</span><span class="p">,</span> <span class="n">DL</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(),</span> <span class="nb">list</span><span class="p">()</span>

            <span class="c1"># Gradient descent iterations (local optimization)</span>
            <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">maxiter</span><span class="p">):</span>

                <span class="c1"># Compute gradients</span>
                <span class="n">grad_x_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_grad_x_loss</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">s</span><span class="p">],</span> <span class="n">Y</span><span class="p">[</span><span class="n">s</span><span class="p">,</span> <span class="p">:],</span>
                                            <span class="bp">self</span><span class="o">.</span><span class="n">k0_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">k1_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">k2_</span><span class="p">,</span>
                                            <span class="bp">self</span><span class="o">.</span><span class="n">g_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_</span><span class="p">)</span>

                <span class="c1"># Update parameters</span>
                <span class="n">x</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="o">-</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">grad_x_</span>

                <span class="c1"># Update loss</span>
                <span class="n">L</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">s</span><span class="p">],</span> <span class="n">Y</span><span class="p">[</span><span class="n">s</span><span class="p">,</span> <span class="p">:],</span>
                                    <span class="bp">self</span><span class="o">.</span><span class="n">k0_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">k1_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">k2_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">g_</span><span class="p">,</span>
                                    <span class="bp">self</span><span class="o">.</span><span class="n">b_</span><span class="p">))</span>

                <span class="c1"># Update delta loss and check for convergence</span>
                <span class="k">if</span> <span class="n">t</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">DL</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">L</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">L</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">])</span>
                    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">DL</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">L</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="o">&lt;</span> <span class="n">convergence_threshold</span><span class="p">:</span>
                        <span class="n">msg</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="se">\t</span><span class="s1"> Converged. Loss function: </span><span class="si">{0:.2f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                            <span class="n">L</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
                        <span class="c1"># logger.info(msg)</span>
                        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                            <span class="c1"># if True:</span>
                            <span class="nb">print</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
                        <span class="k">break</span>

        <span class="c1"># Make sure x is between [-pi, pi]</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arctan2</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">x</span></div>

<div class="viewcode-block" id="NeuroPop.display"><a class="viewcode-back" href="../../../api/ml.html#spykes.ml.neuropop.NeuroPop.display">[docs]</a>    <span class="k">def</span> <span class="nf">display</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">neuron</span><span class="p">,</span> <span class="n">colors</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="s1">&#39;c&#39;</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">ylim</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">25</span><span class="p">],</span>
                <span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;direction [radians]&#39;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;firing rate [spk/s]&#39;</span><span class="p">,</span>
                <span class="n">style</span><span class="o">=</span><span class="s1">&#39;../mpl_styles/spykes.mplstyle&#39;</span><span class="p">,</span>
                <span class="n">xjitter</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">yjitter</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Visualize data and estimated tuning curves</span>

<span class="sd">        Args:</span>
<span class="sd">            x (float): :data:`n_samples x 1`, feature of interest.</span>
<span class="sd">            Y (float): :data:`n_samples x 1`, firing rates.</span>
<span class="sd">            neuron (int): Which neuron&#39;s fit to plot from the population?</span>
<span class="sd">            colors (list of str): Plot strings that specify color for raw data</span>
<span class="sd">                and fit.</span>
<span class="sd">            alpha (float): Transparency for raw data.</span>
<span class="sd">            ylim (list of float): Y axis limits.</span>
<span class="sd">            xlabel (str): X label (typically name of the feature).</span>
<span class="sd">            ylabel (str): Y label (typically firing rate).</span>
<span class="sd">            style (str): Name of the mpl style file to use with path.</span>
<span class="sd">            xjitter (bool): Whether to add jitter to x variable while plotting.</span>
<span class="sd">            ylitter (bool): Whether to add jitter to y variable while plotting.</span>
<span class="sd">        &#39;&#39;&#39;</span>

        <span class="n">utils</span><span class="o">.</span><span class="n">set_matplotlib_defaults</span><span class="p">(</span><span class="n">plt</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">xjitter</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
            <span class="n">x_jitter</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="mi">32</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">x_jitter</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">yjitter</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
            <span class="n">y_range</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>
            <span class="n">Y_jitter</span> <span class="o">=</span> <span class="n">y_range</span> <span class="o">/</span> <span class="mf">20.0</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">Y_jitter</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">x_jitter</span><span class="p">,</span> <span class="n">Y</span> <span class="o">+</span> <span class="n">Y_jitter</span><span class="p">,</span> <span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">)</span>

        <span class="n">x_range</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="mi">32</span><span class="p">)</span>
        <span class="n">Yhat_range</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tunefun</span><span class="p">(</span><span class="n">x_range</span><span class="p">,</span>
                                   <span class="bp">self</span><span class="o">.</span><span class="n">k0_</span><span class="p">[</span><span class="n">neuron</span><span class="p">],</span>
                                   <span class="bp">self</span><span class="o">.</span><span class="n">k1_</span><span class="p">[</span><span class="n">neuron</span><span class="p">],</span>
                                   <span class="bp">self</span><span class="o">.</span><span class="n">k2_</span><span class="p">[</span><span class="n">neuron</span><span class="p">],</span>
                                   <span class="bp">self</span><span class="o">.</span><span class="n">g_</span><span class="p">[</span><span class="n">neuron</span><span class="p">],</span>
                                   <span class="bp">self</span><span class="o">.</span><span class="n">b_</span><span class="p">[</span><span class="n">neuron</span><span class="p">])</span>

        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_range</span><span class="p">,</span> <span class="n">Yhat_range</span><span class="p">,</span> <span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="n">ylim</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">xlabel</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">ylabel</span><span class="p">)</span>

        <span class="n">plt</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
        <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;top&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;right&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span></div>

<div class="viewcode-block" id="NeuroPop.score"><a class="viewcode-back" href="../../../api/ml.html#spykes.ml.neuropop.NeuroPop.score">[docs]</a>    <span class="k">def</span> <span class="nf">score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">Yhat</span><span class="p">,</span> <span class="n">Ynull</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;circ_corr&#39;</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;Scores the model.</span>

<span class="sd">        Args:</span>
<span class="sd">            Y (array): The true firing rates, an array with shape</span>
<span class="sd">                :data:`(n_samples, n_neurons)`.</span>
<span class="sd">            Yhat (array): The estimated firing rates, an array with shape</span>
<span class="sd">                :data:`(n_samples, [n_neurons])`.</span>
<span class="sd">            Ynull (array or None): The labels of the null model. Must be None</span>
<span class="sd">                if :data:`method` is not :data:`pseudo_R2`. The array has</span>
<span class="sd">                shape :data:`(n_samples, [n_classes])`.</span>
<span class="sd">            method (str): One of :data:`pseudo_R2`, :data:`circ_corr`, or</span>
<span class="sd">                :data:`cosine_dist`.</span>

<span class="sd">        Returns:</span>
<span class="sd">            scalar float: The computed score.</span>
<span class="sd">        &#39;&#39;&#39;</span>

        <span class="k">if</span> <span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;pseudo_R2&#39;</span><span class="p">:</span>
            <span class="k">if</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">):</span>
                <span class="c1"># There are many neurons, so calculate and return the score for</span>
                <span class="c1"># each neuron</span>
                <span class="n">score</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
                <span class="k">for</span> <span class="n">neuron</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
                    <span class="n">L1</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">log_likelihood</span><span class="p">(</span><span class="n">Y</span><span class="p">[:,</span> <span class="n">neuron</span><span class="p">],</span> <span class="n">Yhat</span><span class="p">[:,</span> <span class="n">neuron</span><span class="p">])</span>
                    <span class="n">LS</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">log_likelihood</span><span class="p">(</span><span class="n">Y</span><span class="p">[:,</span> <span class="n">neuron</span><span class="p">],</span> <span class="n">Y</span><span class="p">[:,</span> <span class="n">neuron</span><span class="p">])</span>
                    <span class="n">L0</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">log_likelihood</span><span class="p">(</span><span class="n">Y</span><span class="p">[:,</span> <span class="n">neuron</span><span class="p">],</span> <span class="n">Ynull</span><span class="p">[</span><span class="n">neuron</span><span class="p">])</span>
                    <span class="n">score</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="p">(</span><span class="n">LS</span> <span class="o">-</span> <span class="n">L1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">LS</span> <span class="o">-</span> <span class="n">L0</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">L1</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">log_likelihood</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">Yhat</span><span class="p">)</span>
                <span class="n">LS</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">log_likelihood</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
                <span class="n">L0</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">log_likelihood</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">Ynull</span><span class="p">)</span>
                <span class="n">score</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="p">(</span><span class="n">LS</span> <span class="o">-</span> <span class="n">L1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">LS</span> <span class="o">-</span> <span class="n">L0</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;circ_corr&#39;</span><span class="p">:</span>
            <span class="n">score</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">circ_corr</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">Y</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">Yhat</span><span class="p">))</span>
        <span class="k">elif</span> <span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;cosine_dist&#39;</span><span class="p">:</span>
            <span class="n">score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">Yhat</span><span class="p">)))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Invalid method: &quot;</span><span class="si">{}</span><span class="s1">&quot;. Must &quot;pseudo_R2&quot;, &#39;</span>
                             <span class="s1">&#39;&quot;circ_corr&quot; or &quot;cosine_dist&quot;.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">method</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">score</span></div></div>
</pre></div>

           </div>
           <div class="articleComments">
            
           </div>
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2016, KordingLab.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../../../',
            VERSION:'',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../../../_static/jquery.js"></script>
      <script type="text/javascript" src="../../../_static/underscore.js"></script>
      <script type="text/javascript" src="../../../_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="../../../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>